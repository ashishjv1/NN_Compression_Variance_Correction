{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ashis\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\ashis\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "# import os\n",
    "# import random\n",
    "# import numpy as np\n",
    "# import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim\n",
    "import torch.nn.functional as F\n",
    "# import torch.backends.cudnn as cudnn\n",
    "# from torch.autograd import Variable\n",
    "import torch.nn.parallel\n",
    "from decompositions import compress_layers\n",
    "# import model_loader_cifar\n",
    "# import dataloader\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(net):\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "            init.kaiming_normal_(m.weight, mode='fan_in')\n",
    "            if m.bias is not None:\n",
    "                init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            init.constant_(m.weight, 1)\n",
    "            init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            init.normal_(m.weight, std=1e-3)\n",
    "            if m.bias is not None:\n",
    "                init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "\n",
    "###Prepare Data and transform\n",
    "transform = transforms.Compose([transforms.RandomHorizontalFlip(), transforms.PILToTensor(),\n",
    "transforms.ConvertImageDtype(torch.float),\n",
    "transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "# transforms.RandomErasing(),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10('./root', download=True, train=False, transform=transform)\n",
    "train_set = torchvision.datasets.CIFAR10('./root', download=True, train=True, transform=transform)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [06:24<08:44, 65.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10999,. Rec. error: tensor(1.0254, grad_fn=<DivBackward0>), Variance tensor(0.2308, grad_fn=<AddBackward0>)\n",
      "Compressing layer: layer3.0.conv2\n",
      "Tucker Decomposing...\n",
      "Optimizer: local\n",
      "Epoch 999,. Rec. error: tensor(0.9906, grad_fn=<DivBackward0>), Variance tensor(0.1633, grad_fn=<AddBackward0>)\n",
      "Epoch 1999,. Rec. error: tensor(0.9868, grad_fn=<DivBackward0>), Variance tensor(0.2266, grad_fn=<AddBackward0>)\n",
      "Epoch 2999,. Rec. error: tensor(0.9912, grad_fn=<DivBackward0>), Variance tensor(0.3026, grad_fn=<AddBackward0>)\n",
      "Epoch 3999,. Rec. error: tensor(0.9885, grad_fn=<DivBackward0>), Variance tensor(0.4353, grad_fn=<AddBackward0>)\n",
      "Epoch 4999,. Rec. error: tensor(0.9877, grad_fn=<DivBackward0>), Variance tensor(0.4814, grad_fn=<AddBackward0>)\n",
      "Epoch 5999,. Rec. error: tensor(0.9847, grad_fn=<DivBackward0>), Variance tensor(0.4721, grad_fn=<AddBackward0>)\n",
      "Epoch 6999,. Rec. error: tensor(0.9900, grad_fn=<DivBackward0>), Variance tensor(0.5945, grad_fn=<AddBackward0>)\n",
      "Epoch 7999,. Rec. error: tensor(0.9870, grad_fn=<DivBackward0>), Variance tensor(0.6696, grad_fn=<AddBackward0>)\n",
      "Epoch 8999,. Rec. error: tensor(0.9877, grad_fn=<DivBackward0>), Variance tensor(0.7577, grad_fn=<AddBackward0>)\n",
      "Epoch 9999,. Rec. error: tensor(0.9874, grad_fn=<DivBackward0>), Variance tensor(0.7280, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [06:36<05:44, 49.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10999,. Rec. error: tensor(0.9838, grad_fn=<DivBackward0>), Variance tensor(0.8346, grad_fn=<AddBackward0>)\n",
      "Compressing layer: layer3.0.downsample.0\n",
      "Tucker Decomposing...\n",
      "Optimizer: local\n",
      "Epoch 999,. Rec. error: tensor(1.0293, grad_fn=<DivBackward0>), Variance tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "Epoch 1999,. Rec. error: tensor(1.0230, grad_fn=<DivBackward0>), Variance tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "Epoch 2999,. Rec. error: tensor(1.0226, grad_fn=<DivBackward0>), Variance tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "Epoch 3999,. Rec. error: tensor(1.0243, grad_fn=<DivBackward0>), Variance tensor(0.1037, grad_fn=<AddBackward0>)\n",
      "Epoch 4999,. Rec. error: tensor(1.0240, grad_fn=<DivBackward0>), Variance tensor(0.1235, grad_fn=<AddBackward0>)\n",
      "Epoch 5999,. Rec. error: tensor(1.0252, grad_fn=<DivBackward0>), Variance tensor(0.1433, grad_fn=<AddBackward0>)\n",
      "Epoch 6999,. Rec. error: tensor(1.0249, grad_fn=<DivBackward0>), Variance tensor(0.1643, grad_fn=<AddBackward0>)\n",
      "Epoch 7999,. Rec. error: tensor(1.0243, grad_fn=<DivBackward0>), Variance tensor(0.1823, grad_fn=<AddBackward0>)\n",
      "Epoch 8999,. Rec. error: tensor(1.0239, grad_fn=<DivBackward0>), Variance tensor(0.1969, grad_fn=<AddBackward0>)\n",
      "Epoch 9999,. Rec. error: tensor(1.0242, grad_fn=<DivBackward0>), Variance tensor(0.2121, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [08:43<07:16, 72.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10999,. Rec. error: tensor(1.0241, grad_fn=<DivBackward0>), Variance tensor(0.2284, grad_fn=<AddBackward0>)\n",
      "Compressing layer: layer3.1.conv1\n",
      "Tucker Decomposing...\n",
      "Optimizer: local\n",
      "Epoch 999,. Rec. error: tensor(1.0296, grad_fn=<DivBackward0>), Variance tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "Epoch 1999,. Rec. error: tensor(1.0225, grad_fn=<DivBackward0>), Variance tensor(0.0856, grad_fn=<AddBackward0>)\n",
      "Epoch 2999,. Rec. error: tensor(1.0225, grad_fn=<DivBackward0>), Variance tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "Epoch 3999,. Rec. error: tensor(1.0225, grad_fn=<DivBackward0>), Variance tensor(0.1059, grad_fn=<AddBackward0>)\n",
      "Epoch 4999,. Rec. error: tensor(1.0241, grad_fn=<DivBackward0>), Variance tensor(0.1306, grad_fn=<AddBackward0>)\n",
      "Epoch 5999,. Rec. error: tensor(1.0240, grad_fn=<DivBackward0>), Variance tensor(0.1538, grad_fn=<AddBackward0>)\n",
      "Epoch 6999,. Rec. error: tensor(1.0243, grad_fn=<DivBackward0>), Variance tensor(0.1710, grad_fn=<AddBackward0>)\n",
      "Epoch 7999,. Rec. error: tensor(1.0246, grad_fn=<DivBackward0>), Variance tensor(0.1861, grad_fn=<AddBackward0>)\n",
      "Epoch 8999,. Rec. error: tensor(1.0247, grad_fn=<DivBackward0>), Variance tensor(0.2029, grad_fn=<AddBackward0>)\n",
      "Epoch 9999,. Rec. error: tensor(1.0248, grad_fn=<DivBackward0>), Variance tensor(0.2195, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15/20 [10:48<07:22, 88.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10999,. Rec. error: tensor(1.0246, grad_fn=<DivBackward0>), Variance tensor(0.2362, grad_fn=<AddBackward0>)\n",
      "Compressing layer: layer3.1.conv2\n",
      "Tucker Decomposing...\n",
      "Optimizer: local\n",
      "Epoch 999,. Rec. error: tensor(1.0452, grad_fn=<DivBackward0>), Variance tensor(0.0302, grad_fn=<AddBackward0>)\n",
      "Epoch 1999,. Rec. error: tensor(1.0326, grad_fn=<DivBackward0>), Variance tensor(0.0233, grad_fn=<AddBackward0>)\n",
      "Epoch 2999,. Rec. error: tensor(1.0371, grad_fn=<DivBackward0>), Variance tensor(0.0419, grad_fn=<AddBackward0>)\n",
      "Epoch 3999,. Rec. error: tensor(1.0378, grad_fn=<DivBackward0>), Variance tensor(0.0589, grad_fn=<AddBackward0>)\n",
      "Epoch 4999,. Rec. error: tensor(1.0372, grad_fn=<DivBackward0>), Variance tensor(0.0668, grad_fn=<AddBackward0>)\n",
      "Epoch 5999,. Rec. error: tensor(1.0371, grad_fn=<DivBackward0>), Variance tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "Epoch 6999,. Rec. error: tensor(1.0366, grad_fn=<DivBackward0>), Variance tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "Epoch 7999,. Rec. error: tensor(1.0366, grad_fn=<DivBackward0>), Variance tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "Epoch 8999,. Rec. error: tensor(1.0365, grad_fn=<DivBackward0>), Variance tensor(0.0976, grad_fn=<AddBackward0>)\n",
      "Epoch 9999,. Rec. error: tensor(1.0367, grad_fn=<DivBackward0>), Variance tensor(0.1083, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [16:00<10:23, 155.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10999,. Rec. error: tensor(1.0365, grad_fn=<DivBackward0>), Variance tensor(0.1195, grad_fn=<AddBackward0>)\n",
      "Compressing layer: layer4.0.conv1\n",
      "Tucker Decomposing...\n",
      "Optimizer: local\n",
      "Epoch 999,. Rec. error: tensor(1.0301, grad_fn=<DivBackward0>), Variance tensor(0.0377, grad_fn=<AddBackward0>)\n",
      "Epoch 1999,. Rec. error: tensor(1.0229, grad_fn=<DivBackward0>), Variance tensor(0.0431, grad_fn=<AddBackward0>)\n",
      "Epoch 2999,. Rec. error: tensor(1.0221, grad_fn=<DivBackward0>), Variance tensor(0.0455, grad_fn=<AddBackward0>)\n",
      "Epoch 3999,. Rec. error: tensor(1.0226, grad_fn=<DivBackward0>), Variance tensor(0.0544, grad_fn=<AddBackward0>)\n",
      "Epoch 4999,. Rec. error: tensor(1.0244, grad_fn=<DivBackward0>), Variance tensor(0.0653, grad_fn=<AddBackward0>)\n",
      "Epoch 5999,. Rec. error: tensor(1.0244, grad_fn=<DivBackward0>), Variance tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "Epoch 6999,. Rec. error: tensor(1.0247, grad_fn=<DivBackward0>), Variance tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "Epoch 7999,. Rec. error: tensor(1.0247, grad_fn=<DivBackward0>), Variance tensor(0.0934, grad_fn=<AddBackward0>)\n",
      "Epoch 8999,. Rec. error: tensor(1.0246, grad_fn=<DivBackward0>), Variance tensor(0.1029, grad_fn=<AddBackward0>)\n",
      "Epoch 9999,. Rec. error: tensor(1.0249, grad_fn=<DivBackward0>), Variance tensor(0.1115, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [25:19<13:50, 276.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10999,. Rec. error: tensor(1.0249, grad_fn=<DivBackward0>), Variance tensor(0.1191, grad_fn=<AddBackward0>)\n",
      "Compressing layer: layer4.0.conv2\n",
      "Tucker Decomposing...\n",
      "Optimizer: local\n",
      "Epoch 999,. Rec. error: tensor(0.9884, grad_fn=<DivBackward0>), Variance tensor(0.0686, grad_fn=<AddBackward0>)\n",
      "Epoch 1999,. Rec. error: tensor(0.9844, grad_fn=<DivBackward0>), Variance tensor(0.0909, grad_fn=<AddBackward0>)\n",
      "Epoch 2999,. Rec. error: tensor(0.9857, grad_fn=<DivBackward0>), Variance tensor(0.1305, grad_fn=<AddBackward0>)\n",
      "Epoch 3999,. Rec. error: tensor(0.9904, grad_fn=<DivBackward0>), Variance tensor(0.1758, grad_fn=<AddBackward0>)\n",
      "Epoch 4999,. Rec. error: tensor(0.9899, grad_fn=<DivBackward0>), Variance tensor(0.1921, grad_fn=<AddBackward0>)\n",
      "Epoch 5999,. Rec. error: tensor(0.9848, grad_fn=<DivBackward0>), Variance tensor(0.2159, grad_fn=<AddBackward0>)\n",
      "Epoch 6999,. Rec. error: tensor(0.9889, grad_fn=<DivBackward0>), Variance tensor(0.2530, grad_fn=<AddBackward0>)\n",
      "Epoch 7999,. Rec. error: tensor(0.9878, grad_fn=<DivBackward0>), Variance tensor(0.2707, grad_fn=<AddBackward0>)\n",
      "Epoch 8999,. Rec. error: tensor(0.9882, grad_fn=<DivBackward0>), Variance tensor(0.2916, grad_fn=<AddBackward0>)\n",
      "Epoch 9999,. Rec. error: tensor(0.9873, grad_fn=<DivBackward0>), Variance tensor(0.3164, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [25:40<06:40, 200.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10999,. Rec. error: tensor(0.9878, grad_fn=<DivBackward0>), Variance tensor(0.3458, grad_fn=<AddBackward0>)\n",
      "Compressing layer: layer4.0.downsample.0\n",
      "Tucker Decomposing...\n",
      "Optimizer: local\n",
      "Epoch 999,. Rec. error: tensor(1.0294, grad_fn=<DivBackward0>), Variance tensor(0.0374, grad_fn=<AddBackward0>)\n",
      "Epoch 1999,. Rec. error: tensor(1.0228, grad_fn=<DivBackward0>), Variance tensor(0.0427, grad_fn=<AddBackward0>)\n",
      "Epoch 2999,. Rec. error: tensor(1.0221, grad_fn=<DivBackward0>), Variance tensor(0.0450, grad_fn=<AddBackward0>)\n",
      "Epoch 3999,. Rec. error: tensor(1.0231, grad_fn=<DivBackward0>), Variance tensor(0.0540, grad_fn=<AddBackward0>)\n",
      "Epoch 4999,. Rec. error: tensor(1.0237, grad_fn=<DivBackward0>), Variance tensor(0.0648, grad_fn=<AddBackward0>)\n",
      "Epoch 5999,. Rec. error: tensor(1.0248, grad_fn=<DivBackward0>), Variance tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "Epoch 6999,. Rec. error: tensor(1.0248, grad_fn=<DivBackward0>), Variance tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "Epoch 7999,. Rec. error: tensor(1.0249, grad_fn=<DivBackward0>), Variance tensor(0.0938, grad_fn=<AddBackward0>)\n",
      "Epoch 8999,. Rec. error: tensor(1.0252, grad_fn=<DivBackward0>), Variance tensor(0.1030, grad_fn=<AddBackward0>)\n",
      "Epoch 9999,. Rec. error: tensor(1.0251, grad_fn=<DivBackward0>), Variance tensor(0.1124, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19/20 [35:10<05:11, 311.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10999,. Rec. error: tensor(1.0256, grad_fn=<DivBackward0>), Variance tensor(0.1207, grad_fn=<AddBackward0>)\n",
      "Compressing layer: layer4.1.conv1\n",
      "Tucker Decomposing...\n",
      "Optimizer: local\n",
      "Epoch 999,. Rec. error: tensor(1.0294, grad_fn=<DivBackward0>), Variance tensor(0.0367, grad_fn=<AddBackward0>)\n",
      "Epoch 1999,. Rec. error: tensor(1.0227, grad_fn=<DivBackward0>), Variance tensor(0.0415, grad_fn=<AddBackward0>)\n",
      "Epoch 2999,. Rec. error: tensor(1.0223, grad_fn=<DivBackward0>), Variance tensor(0.0436, grad_fn=<AddBackward0>)\n",
      "Epoch 3999,. Rec. error: tensor(1.0231, grad_fn=<DivBackward0>), Variance tensor(0.0525, grad_fn=<AddBackward0>)\n",
      "Epoch 4999,. Rec. error: tensor(1.0239, grad_fn=<DivBackward0>), Variance tensor(0.0638, grad_fn=<AddBackward0>)\n",
      "Epoch 5999,. Rec. error: tensor(1.0245, grad_fn=<DivBackward0>), Variance tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "Epoch 6999,. Rec. error: tensor(1.0248, grad_fn=<DivBackward0>), Variance tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "Epoch 7999,. Rec. error: tensor(1.0246, grad_fn=<DivBackward0>), Variance tensor(0.0935, grad_fn=<AddBackward0>)\n",
      "Epoch 8999,. Rec. error: tensor(1.0246, grad_fn=<DivBackward0>), Variance tensor(0.1019, grad_fn=<AddBackward0>)\n",
      "Epoch 9999,. Rec. error: tensor(1.0246, grad_fn=<DivBackward0>), Variance tensor(0.1097, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [44:43<00:00, 134.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10999,. Rec. error: tensor(1.0250, grad_fn=<DivBackward0>), Variance tensor(0.1170, grad_fn=<AddBackward0>)\n",
      "Compressing layer: layer4.1.conv2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=False)\n",
    "device = \"cuda\"\n",
    "names_to_compress = [module_name for module_name, module in model.named_modules()\n",
    "                              if isinstance(module, nn.Conv2d)]\n",
    "# init_params(model)\n",
    "#         print(model)\n",
    "CNET, net = compress_layers(model,  key='tucker2', lr=0.0001, penalty=0.6, n_iter=1100)\n",
    "#         print(net)\n",
    "# torch.save(net, 'save_models/' + str(model) + 'full' + '.pth')\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of model parameters: 6249609\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "94640030208"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flopco import FlopCo\n",
    "print('Number of model parameters: {}'.format(\n",
    "    sum([p.data.nelement() for p in net.parameters()])))\n",
    "print('')\n",
    "\n",
    "\n",
    "model = net.to(device)\n",
    "\n",
    "\n",
    "stats = FlopCo(model, img_size = (1, 3, 256, 128), device = device)\n",
    "\n",
    "# print(stats.total_macs, stats.relative_flops)\n",
    "relative_flops_dict = stats.total_flops\n",
    "relative_flops_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.249609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [03:37<2:57:39, 217.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num parameters 6.249609\n",
      "current loss 2.4924825937747954\n",
      "current accuracy 42.012\n"
     ]
    }
   ],
   "source": [
    "from torch import linalg as LA\n",
    "\n",
    "######TESTS WITHOUT NORM CONSTRAINT ON THE LOSS FUNCTION######\n",
    "\n",
    "# import math\n",
    "# from torch import linalg as LA\n",
    "###Training shite\n",
    "running_loss = 0.0\n",
    "loss_list = list()\n",
    "correct = 0\n",
    "total = 0 \n",
    "\n",
    "# net = models.resnet18(pretrained=False)\n",
    "\n",
    "print(sum(p.numel() for p in net.parameters()) / 1000000)\n",
    "\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "lr = 0.01\n",
    "weight_decay = 0.001\n",
    "criterion = nn.NLLLoss() \n",
    "\n",
    "epochs = 50\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    for idx, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)  \n",
    "\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = net(inputs)\n",
    "        loss = criterion(F.log_softmax(output, dim=1), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "        # correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "        correct += pred.eq(labels.view(-1, 1)).sum().item()\n",
    "        # correct += (pred == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        accuracy = 100. * correct / total \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    \n",
    "    print(\"num parameters\", sum(p.numel() for p in net.parameters()) / 1000000)\n",
    "    print(\"current loss\", running_loss / 1000)\n",
    "    running_loss = 0.0\n",
    "    print(\"current accuracy\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
